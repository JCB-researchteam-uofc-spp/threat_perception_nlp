{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27877b9a-0b38-4f38-b42a-f3110adba20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and Preprocess the Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"your_combined_dataset.csv\")  # Update with your file name\n",
    "\n",
    "# Encode label column\n",
    "label_map = {label: idx for idx, label in enumerate(df[\"Label\"].unique())}\n",
    "df[\"Label\"] = df[\"Label\"].map(label_map)\n",
    "\n",
    "# Split into train and validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"Paragraph\"].tolist(), df[\"Label\"].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264d985-ff0e-495f-adef-0f22545d1932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch Dataset\n",
    "import torch\n",
    "\n",
    "class ThreatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = ThreatDataset(train_encodings, train_labels)\n",
    "val_dataset = ThreatDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded51149-91fa-41c5-9631-49dec083087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pretrained RoBERTa\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "num_labels = len(label_map)\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=num_labels)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26704a34-24d6-49fb-b424-beddb8c656af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Training Arguments & Trainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36570f0-b0ff-458a-93a6-ba6f7304f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a5a92-f82f-45be-8962-f4729e7a889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate predictions\n",
    "def get_predictions(dataset):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    for batch in torch.utils.data.DataLoader(dataset, batch_size=8):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "        true_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "    return np.array(predictions), np.array(true_labels)\n",
    "\n",
    "val_preds, val_labels = get_predictions(val_dataset)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(val_labels, val_preds)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "label_names = list(label_map.keys())\n",
    "report_dict = classification_report(val_labels, val_preds, target_names=label_names, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df.loc[\"accuracy\"] = [accuracy, None, None, None]\n",
    "report_df.to_csv(\"classification_report_with_accuracy.csv\", float_format=\"%.4f\")\n",
    "print(report_df)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(val_labels, val_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_names, yticklabels=label_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5098204e-4446-400b-ac2c-ff7bfdbe31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Best Model Later\n",
    "\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "best_model_path = \"./results/checkpoint-xxxx\"  # Replace with your checkpoint folder\n",
    "model = RobertaForSequenceClassification.from_pretrained(best_model_path)\n",
    "model.to(device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
